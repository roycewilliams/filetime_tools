### scanner.py
###
### part of the file system change
### scans the file system

############################################################
############################################################

__version__ = '0.1.0'
import os
import sys
import zipfile
import time
from dbfile import DBFile, SLGSQL
import sqlite3


COMMIT_RATE = 10  # commit every 10 directories

def hash_file(f):
    """High performance file hasher. Hash a file and return the MD5 hexdigest."""
    from hashlib import md5
    m = md5()
    while True:
        buf = f.read(65535)
        if not buf:
            return m.hexdigest()
        m.update(buf)

def open_zipfile(path):
    """Check to see if path is a zipfile.
    If so, return an open zipfile"""
    if path.lower().endswith(".jar"):           # Don't peek inside jar files
        return None
    try:
        return zipfile.ZipFile(path,mode="r")
    except zipfile.BadZipfile:
        return None
    except zipfile.LargeZipFile:
        return None
    except OSError as e:
        print("OSError: {}".format(e))
        return None

class Scanner(object):
    """Class to scan a directory and store the results in the database."""
    def __init__(self, conn):
        self.conn = conn
        self.c = self.conn.cursor()
        self.args = args
        self.filecount = 0
        self.dircount = 0

    def get_hashid(self, hexhash):
        self.conn.execute("INSERT or IGNORE INTO hashes (hash) VALUES (?);", (hexhash,))
        for row in self.conn.execute("SELECT hashid FROM hashes WHERE hash=? LIMIT 1", (hexhash,)):
            return row[0]

    def get_dirnameid(self, dirname):
        self.c.execute("INSERT or IGNORE INTO dirnames (dirname) VALUES (?);", (dirname,))
        self.c.execute("SELECT dirnameid FROM dirnames WHERE dirname=?", (dirname,))
        return self.c.fetchone()[0]

    def get_filenameid(self, filename):
        assert "/" not in filename
        self.c.execute("INSERT or IGNORE INTO filenames (filename) VALUES (?);", (filename,))
        self.c.execute("SELECT filenameid FROM filenames WHERE filename=?", (filename,))
        return self.c.fetchone()[0]

    def get_pathid(self, path):
        (dirname, filename) = os.path.split(path)
        dirnameid = self.get_dirnameid(dirname)
        filenameid = self.get_filenameid(filename)

        # pathid
        self.c.execute("INSERT or IGNORE INTO paths (dirnameid,filenameid) VALUES (?,?);",
                       (dirnameid, filenameid,))
        self.c.execute("SELECT pathid FROM paths WHERE dirnameid=? AND filenameid=?",
                       (dirnameid, filenameid,))
        return self.c.fetchone()[0]

    def get_scanida(self, now, root):
        dirnameid = self.get_dirnameid(root)
        self.c.execute("INSERT or IGNORE INTO scans (time) VALUES (?);", (now,))
        self.c.execute("SELECT scanid FROM scans WHERE time=?", (now,))
        scanid = self.c.fetchone()[0]
        self.c.execute("INSERT INTO roots (scanid,dirnameid) values (?,?)",(scanid,dirnameid))
        self.conn.commit()
        return scanid

    def get_scanidb(self, now):
        self.conn.execute("INSERT or IGNORE INTO scans (time) VALUES (?);", (now,))
        for row in self.conn.execute("SELECT scanid FROM scans WHERE time=? LIMIT 1", (now,)):
            return row[0]

    def insert_file(self, path, mtime, file_size, handle, scanid):
        """@mtime in time_t"""

        if self.verbose_files:
            print("insert_file({})".format(path))

        pathid = self.get_pathid(path)

    def get_pathid(self,  path):
        (dirname, filename) = os.path.split(path)
        # dirname
        self.conn.execute("INSERT or IGNORE INTO dirnames (dirname) VALUES (?);", (dirname,))
        for row in self.conn.execute("SELECT dirnameid FROM dirnames WHERE dirname=? LIMIT 1", (dirname,)):
            dirnameid = row[0]

        # filename
        self.conn.execute("INSERT or IGNORE INTO filenames (filename) VALUES (?);", (filename,))
        for row in self.conn.execute("SELECT filenameid FROM filenames WHERE filename=?", (filename,)):
            filenameid = row[0]

        # pathid
        self.conn.execute("INSERT or IGNORE INTO paths (dirnameid,filenameid) VALUES (?,?);",
                          (dirnameid, filenameid,))
        for row in self.conn.execute("SELECT pathid FROM paths WHERE dirnameid=? AND filenameid=? LIMIT 1",
                                     (dirnameid, filenameid,)):
            return row[0]
        raise RuntimeError(f"no pathid found for {dirnameid},{filenameid}")

    def get_file_hashid(self, *, f=None, pathname=None, file_size, pathid=None, mtime, hexdigest=None):
        """Given an open file or a filename, Return the MD5 hexdigest."""
        if pathid is None:
            if pathname is None:
                raise RuntimeError("pathid and pathname are both None")
            pathid = self.get_pathid(pathname)

        # See if this file with this length is in the database.
        # If not, we will hash the file and enter it.
        # This means that we are trusting that the mtime gets updated if the file contents change.
        # We might also want to look at the file generation count.
        for row in self.conn.execute("SELECT hashid FROM files WHERE pathid=? AND mtime=? AND size=? LIMIT 1",
                                     (pathid, mtime, file_size)):
            return row[0]

        # Hashid is not in the database. Hash the file if we don't have the hash
        if hexdigest is None:
            if f is None:
                f = open(pathname,'rb')

            from hashlib import md5
            m = md5()
            while True:
                buf = f.read(65535)
                if not buf:
                    break
                m.update(buf)
            hexdigest = m.hexdigest()
        return self.get_hashid( hexdigest )
        

    def insert_file(self, *, path, mtime, file_size, handle=None, hexdigest=None):
        """@mtime in time_t"""
        pathid = self.get_pathid(path)

        try:
            hashid = self.get_file_hashid(pathid=pathid,mtime=mtime,file_size=file_size,f=handle, hexdigest=hexdigest)
        except PermissionError as e:
            return
        except OSError as e:
            return

        self.conn.execute("INSERT INTO files (pathid,mtime,size,hashid,scanid) VALUES (?,?,?,?,?)",
                       (pathid, mtime, file_size, hashid, self.scanid))
        if self.args.vfiles:
            print("{} {}".format(path, file_size))

<<<<<<< HEAD
    def process_filepath(self, scanid, path):
=======

    def process_filepath(self, path):
>>>>>>> 0de3f351fc54daed45d661d29cf9b47e6498e0c4
        """ Add the file to the database database.
        If it is there and the mtime hasn't been changed, don't re-hash."""

        try:
            st = os.stat(path)
        except FileNotFoundError as e:
            return

        self.insert_file(path=path, mtime=st.st_mtime, file_size=st.st_size, handle=open(path,"rb"))

    def process_zipfile(self, path, zf):
        """Scan a zip file and insert it into the database"""
        for zi in zf.infolist():
            mtime = time.mktime(zi.date_time + (0,0,0))
<<<<<<< HEAD
            self.insert_file(path+"/"+zi.filename, mtime, zi.file_size,zf.open(zi.filename,"r"), scanid)

    def ingest(self, root, ignore_ext=[], only_ext=[], verbose_dirs=False, verbose_files=False):
        """Ingest everything from the root"""

        self.verbose_dirs = verbose_dirs
        self.verbose_files = verbose_files
        print("verbose_files=",verbose_files)

        if not os.path.exists(root):
            raise FileNotFoundError(root)
        if not os.path.isdir(root):
            raise FileNotFoundError("{} is not a directory".format(root))

        only_ext_lower   = [ext.lower() for ext in only_ext]
        ignore_ext_lower = [ext.lower() for ext in ignore_ext]

        self.c = self.conn.cursor()
        self.c.execute("BEGIN TRANSACTION")

        scanid = self.get_scanid(SLGSQL.iso_now(),root)
=======
            self.insert_file(path=path+"/"+zi.filename, mtime=mtime, file_size=zi.file_size, handle=zf.open(zi.filename,"r"))

    def ingest_start(self, root):
        print("ingest_start")
        self.scanid = self.get_scanid(SLGSQL.iso_now())

>>>>>>> 0de3f351fc54daed45d661d29cf9b47e6498e0c4

    def ingest_walk(self, root):
        """Walk the local file system and go inside ZIP files"""
        for (dirpath, dirnames, filenames) in os.walk(root):
<<<<<<< HEAD
            if verbose_dirs or verbose_files:
                print("scanning {}".format(dirpath))
            for filename in filenames:
                filename_lower = filename.lower()
                if only_ext!=[''] and not any([filename_lower.endswith(ext) for ext in only_ext_lower]):
                    if verbose_files:
                        print("Will not include {} (not in only_ext)".format(filename))
                    continue
                if ignore_ext_lower!=[''] and any([filename_lower.endswith(ext) for ext in ignore_ext_lower]):
                    if verbose_files:
                        print("Will not include {} (in {})".format(filename,ignore_ext_lower))
                    continue

                path = os.path.join(dirpath, filename)
                if not os.path.isfile(path):
                    continue
                self.process_filepath(scanid, path)
                zf = open_zipfile(path)
                if zf:
                    self.process_zipfile(scanid,path, zf)

            if verbose_dirs:
                print("\r{}: scanned {} files".format(dirpath,len(filenames)))
            count += len(filenames)
            dircount += 1
            if dircount % COMMIT_RATE == 0:
                self.conn.commit()

        self.conn.commit()
        t1 = time.time()
        self.c.execute("UPDATE scans SET duration=? WHERE scanid=?", (t1 - t0, scanid))
        self.conn.commit()
        print("Total files added to database: {}".format(count))
        print("Total directories scanned:     {}".format(dircount))
        print("Total time: {}".format(int(t1 - t0)))
=======
            #
            # see https://docs.python.org/3.7/library/sqlite3.html#using-the-connection-as-a-context-manager
            try:
                with self.conn:
                    if self.args.vdirs:
                        print("{}".format(dirpath), end='\n' if self.args.vfiles else '')

                    for filename in filenames:
                        #
                        # Get full path and process
                        filename_path = os.path.join(dirpath, filename)
                        self.process_filepath(filename_path)

                        # See if this is a zipfile. If so, process it
                        zf = open_zipfile(filename_path)
                        if zf:
                            self.process_zipfile( filename_path, zf)
                        self.filecount += 1
                        if (self.args.limit is not None) and (self.filecount > self.args.limit):
                            return

                    if self.args.vdirs:
                        print("\r{}:  {}".format(dirpath,len(filenames)))
                    self.dircount  += 1
            except sqlite3.IntegrityError as e:
                print(e)

    def ingest_done(self, root):
        with self.conn:
            self.conn.execute("UPDATE scans SET duration=? WHERE scanid=?", (self.t1 - self.t0, self.scanid))
        print("Total files added to database: {}".format(self.filecount))
        print("Total directories scanned:     {}".format(self.dircount))
        print("Total time: {}".format(int(self.t1 - self.t0)))
>>>>>>> 0de3f351fc54daed45d661d29cf9b47e6498e0c4

    def ingest(self, root):
        """Ingest everything from the root"""

<<<<<<< HEAD
def get_file_for_hash(conn, hash):
    c = conn.cursor()
    c.execute("SELECT pathid, dirnameid, dirname, filenameid, filename, fileid, mtime, size "
              "FROM files NATURAL JOIN paths NATURAL JOIN dirnames NATURAL JOIN filenames "
              "WHERE hashid=(select hashid from hashes where hash=?)", (hash,))
    return (DBFile(f) for f in c)
    



###################### END OF SCANNER CLASS ######################
##################################################################
=======
        self.ingest_start(root)
        self.t0 = time.time()
        self.ingest_walk(root)
        self.t1 = time.time()
        self.ingest_done(root)


class S3Scanner(Scanner):
    def __init__(self, *args, **kwargs):
        super().__init__(*args,**kwargs)

    def ingest_walk(self, root):
        """Scan S3"""
        (bucket,key) = s3.get_bucket_key(root)
        for obj in s3.list_objects(bucket,key):
            # {'LastModified': '2019-03-28T21:36:51.000Z', 
            #   'ETag': '"46610609053db79a94c4bd29cad8f4ff"', 
            #   'StorageClass': 'STANDARD', 
            #   'Key': 'a/b/c/whatever.txt', 
            #   'Size': 31838630}

            print(obj)
            self.insert_file( path=obj['Key'], mtime=obj['LastModified'], file_size=obj['Size'], hexdigest=obj['ETag'] )
            self.filecount += 1
            if (self.args.limit is not None) and (self.filecount > self.args.limit):
                return
            if self.filecount %100==0:
                self.conn.commit()
        print("Scan S3: ",root)
        
>>>>>>> 0de3f351fc54daed45d661d29cf9b47e6498e0c4

def list_scans(conn):
    c = conn.cursor()
    for (scanid, time, root) in c.execute("SELECT scans.scanid, scans.time, dirnames.dirname FROM scans LEFT JOIN roots on scans.scanid=roots.rootid LEFT JOIN dirnames on roots.dirnameid=dirnames.dirnameid;"):
        print(scanid, time, root)

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description='Scan a directory and report the file changes.',
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument("--db", help="Specify database location", default="data.sqlite3")
    parser.add_argument("--list", help="List the roots and scans in the DB", action='store_true')
    parser.add_argument("--vfiles", help="Report each file as ingested",action="store_true")
    parser.add_argument("--vdirs", help="Report each dir as ingested",action="store_true")
    parser.add_argument("--scan", help="Scan a given directory")
    parser.add_argument("--only_ext", help="Only this extension. Multiple extensions can be provided with commas", default='')
    parser.add_argument("--ignore_ext", help="Ignore this extension. Multiple extensions can be provided with commas", default='')

    args = parser.parse_args()
    if not os.path.exists(args.db):
        create_database(args.db)
        print("Created {}".format(args.db))

    # open database and give me a big cache
    conn = sqlite3.connect(args.db)
    conn.row_factory = sqlite3.Row
    conn.cursor().execute(SQLITE3_SET_CACHE)

    if args.list:
        list_scans(conn)

    if args.scan:
        print("Scanning: {}".format(args.scan))
        scanner = Scanner(conn)
        scanner.ingest(args.scan, verbose_dirs=args.vdirs, verbose_files=args.vfiles,
                       ignore_ext=args.ignore_ext.split(","),
                       only_ext=args.only_ext.split(","))
